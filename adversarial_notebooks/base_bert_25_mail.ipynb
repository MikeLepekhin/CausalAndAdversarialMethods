{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WJfM6R9w_K8"
      },
      "source": [
        "# Training a neural emotion detection using BERT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLKcxpYaE8ub"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7rCsHIWmEBkX"
      },
      "outputs": [],
      "source": [
        "PASTEL_DATASET = '.'\n",
        "!mkdir -p {PASTEL_DATASET}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''import pandas as pd\n",
        "\n",
        "raw_df = pd.read_excel('CLEAR_corpus_final.xlsx')\n",
        "raw_df['text'] = raw_df['Excerpt']\n",
        "raw_df['genre'] = raw_df['BT_easiness']\n",
        "raw_df = raw_df.sample(frac=1.0)\n",
        "\n",
        "train_df = raw_df.iloc[:int(0.8 * len(raw_df))]\n",
        "test_df = raw_df.iloc[int(0.8 * len(raw_df)):]\n",
        "train_df.to_csv(f'{PASTEL_DATASET}/train.csv')\n",
        "test_df.to_csv(f'{PASTEL_DATASET}/test.csv')'''"
      ],
      "metadata": {
        "id": "gGa20MG8N5QD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "78e7e103-c19b-445c-f6c0-dcda098f8ab9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"import pandas as pd\\n\\nraw_df = pd.read_excel('CLEAR_corpus_final.xlsx')\\nraw_df['text'] = raw_df['Excerpt']\\nraw_df['genre'] = raw_df['BT_easiness']\\nraw_df = raw_df.sample(frac=1.0)\\n\\ntrain_df = raw_df.iloc[:int(0.8 * len(raw_df))]\\ntest_df = raw_df.iloc[int(0.8 * len(raw_df)):]\\ntrain_df.to_csv(f'{PASTEL_DATASET}/train.csv')\\ntest_df.to_csv(f'{PASTEL_DATASET}/test.csv')\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CC0yc1pmOMly"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mxB8Ag1FCE3"
      },
      "source": [
        "## 1.1. Using Colab GPU for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24GNUdYRE-jv",
        "outputId": "72ffedc2-dd75-46f0-af9f-913932c7de8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU avaiable, tell PyTorch to use the GPU,\n",
        "# otherwise, using the CPU instead.\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print('We will use the CPU because no GPU available.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdJoYx-IFZNL"
      },
      "source": [
        "## 1.2. Installing the Hugging Face Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1Mf_l2gLo3g"
      },
      "source": [
        "Install the pytorch interface for BERT by Hugging Face."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8QbUEEkwLoCt"
      },
      "outputs": [],
      "source": [
        "#!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OniLT7F0Fns5"
      },
      "source": [
        "# 2. Loading EmoBank Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm3bmG8VI5mA"
      },
      "source": [
        "The dataset that we work on is called EmoBank, which comprises 10k sentences balancing multiple genres.\n",
        "\n",
        "It's hosted on GitHub in this repo: https://github.com/JULIELab/EmoBank"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls {PASTEL_DATASET}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC2_6MbCBFcv",
        "outputId": "2b279f79-19da-48da-d36b-16b1135d0425"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "awd_test_topics.csv  awd_train_topics.csv  mail_test_topics.csv  mail_train_topics.csv\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "young_values = ['0-20', '21-30', '31-45']\n",
        "\n",
        "def is_young(s: str):\n",
        "  return int(s in young_values)"
      ],
      "metadata": {
        "id": "bNYEWivvma8G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "train_mail = pd.read_csv('mail_train_topics.csv').sample(frac=1.0, random_state=42)\n",
        "train_awd = pd.read_csv('awd_train_topics.csv').sample(frac=1.0, random_state=42)\n",
        "train_mail['confounder'] = 1\n",
        "train_awd['confounder'] = 0\n",
        "\n",
        "test_mail = pd.read_csv('mail_test_topics.csv').sample(frac=1.0, random_state=42)\n",
        "test_awd = pd.read_csv('awd_test_topics.csv').sample(frac=1.0, random_state=42)\n",
        "test_mail['confounder'] = 1\n",
        "test_awd['confounder'] = 0\n",
        "\n",
        "assert len(train_mail) == len(train_awd)\n",
        "\n",
        "shift_train_75_mail_25_awd = pd.concat([\n",
        "    train_mail[:int(0.25 * len(train_mail))],\n",
        "    train_awd[:int(0.75 * len(train_awd))]\n",
        "])\n",
        "\n",
        "shift_test_25_mail_75_awd = pd.concat([\n",
        "    train_mail[:int(0.75 * len(test_mail))],\n",
        "    train_awd[:int(0.25 * len(test_awd))]\n",
        "])\n",
        "\n",
        "shift_train_75_mail_25_awd.to_csv('shift_train_75_mail_25_awd.csv')\n",
        "shift_test_25_mail_75_awd.to_csv('shift_test_25_mail_75_awd.csv')\n",
        "shift_test_25_mail_75_awd"
      ],
      "metadata": {
        "id": "Qn0oNjw3HYUa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "245d7ff7-f1d8-43e7-edab-edce59e5e469"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0                                           sentence  topic  \\\n",
              "2215        2215  Скоро мой взлетит самолёт Кто-то объявляет про...   30.0   \n",
              "2582        2582  Ох , уж эти девки , всё бы им ржать ! Когда уж...   11.0   \n",
              "1662        1662  С первым днем Зимы , дорогие друзья ! ! ! Жела...   89.0   \n",
              "3027        3027  Если любовь уходит , какое найти решение ? Мож...   11.0   \n",
              "4343        4343  Моей внучке пять лет . раска . а . а . зчица !...   70.0   \n",
              "...          ...                                                ...    ...   \n",
              "970          970  Таки вот что я отвечу - д . р . у 3 сотруднико...   79.0   \n",
              "2338        2338  Кстати , да . . Тут выше сообщали и о двойном ...   14.0   \n",
              "1263        1263  Jose Luis Cortes y Ng La Banda - En directo de...   79.0   \n",
              "169          169  Хочу Canon 85 1.2 , жаба не душит , просто нет...   55.0   \n",
              "4550        4550  shushlev У меня была такая же ситуация с люфта...   55.0   \n",
              "\n",
              "     genre  confounder  \n",
              "2215     W           1  \n",
              "2582     M           1  \n",
              "1662     W           1  \n",
              "3027     W           1  \n",
              "4343     W           1  \n",
              "...    ...         ...  \n",
              "970      W           0  \n",
              "2338     W           0  \n",
              "1263     W           0  \n",
              "169      M           0  \n",
              "4550     W           0  \n",
              "\n",
              "[1943 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d95ef198-aa48-4428-af99-b7b60cfc6e7b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>sentence</th>\n",
              "      <th>topic</th>\n",
              "      <th>genre</th>\n",
              "      <th>confounder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2215</th>\n",
              "      <td>2215</td>\n",
              "      <td>Скоро мой взлетит самолёт Кто-то объявляет про...</td>\n",
              "      <td>30.0</td>\n",
              "      <td>W</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2582</th>\n",
              "      <td>2582</td>\n",
              "      <td>Ох , уж эти девки , всё бы им ржать ! Когда уж...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>M</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1662</th>\n",
              "      <td>1662</td>\n",
              "      <td>С первым днем Зимы , дорогие друзья ! ! ! Жела...</td>\n",
              "      <td>89.0</td>\n",
              "      <td>W</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3027</th>\n",
              "      <td>3027</td>\n",
              "      <td>Если любовь уходит , какое найти решение ? Мож...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>W</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4343</th>\n",
              "      <td>4343</td>\n",
              "      <td>Моей внучке пять лет . раска . а . а . зчица !...</td>\n",
              "      <td>70.0</td>\n",
              "      <td>W</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970</th>\n",
              "      <td>970</td>\n",
              "      <td>Таки вот что я отвечу - д . р . у 3 сотруднико...</td>\n",
              "      <td>79.0</td>\n",
              "      <td>W</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2338</th>\n",
              "      <td>2338</td>\n",
              "      <td>Кстати , да . . Тут выше сообщали и о двойном ...</td>\n",
              "      <td>14.0</td>\n",
              "      <td>W</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1263</th>\n",
              "      <td>1263</td>\n",
              "      <td>Jose Luis Cortes y Ng La Banda - En directo de...</td>\n",
              "      <td>79.0</td>\n",
              "      <td>W</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>169</td>\n",
              "      <td>Хочу Canon 85 1.2 , жаба не душит , просто нет...</td>\n",
              "      <td>55.0</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4550</th>\n",
              "      <td>4550</td>\n",
              "      <td>shushlev У меня была такая же ситуация с люфта...</td>\n",
              "      <td>55.0</td>\n",
              "      <td>W</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1943 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d95ef198-aa48-4428-af99-b7b60cfc6e7b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d95ef198-aa48-4428-af99-b7b60cfc6e7b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d95ef198-aa48-4428-af99-b7b60cfc6e7b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4bf799a3-deb1-4cf6-b57d-c37aefaabcb9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4bf799a3-deb1-4cf6-b57d-c37aefaabcb9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4bf799a3-deb1-4cf6-b57d-c37aefaabcb9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "shift_test_25_mail_75_awd",
              "summary": "{\n  \"name\": \"shift_test_25_mail_75_awd\",\n  \"rows\": 1943,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2354,\n        \"min\": 17,\n        \"max\": 7993,\n        \"num_unique_values\": 1443,\n        \"samples\": [\n          6342,\n          5002,\n          1417\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1940,\n        \"samples\": [\n          \"\\u041d\\u0435\\u043a\\u043e\\u0442\\u043e\\u0440\\u044b\\u0435 \\u043c\\u043e\\u043c\\u0435\\u043d\\u0442\\u044b \\u0432 \\u0434\\u0430\\u043d\\u043d\\u043e\\u043c \\u043c\\u0438\\u043d\\u0438-\\u043e\\u0442\\u0447\\u0435\\u0442\\u0435 \\u0432 \\u043a\\u0430\\u043a\\u043e\\u043c-\\u0442\\u043e \\u0441\\u043c\\u044b\\u0441\\u043b\\u0435 \\u043e\\u0442\\u0440\\u0430\\u0436\\u0430\\u044e\\u0442 \\u043c\\u043e\\u0435 \\u0441\\u043e\\u0431\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0435 \\u043d\\u0435\\u0440\\u0435\\u0430\\u043b\\u0438\\u0437\\u043e\\u0432\\u0430\\u043d\\u043d\\u043e\\u0435 \\u0432 \\u041f\\u0430\\u0442\\u0442\\u0430\\u0439\\u044f \\u0436\\u0435\\u043b\\u0430\\u043d\\u0438\\u0435 . \\u0410 \\u0438\\u043c\\u0435\\u043d\\u043d\\u043e-\\u043f\\u043e\\u0440\\u043e\\u0439 , \\u0434\\u0435\\u0439\\u0441\\u0442\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\\u043d\\u043e , \\u043e\\u0441\\u043e\\u0431\\u0435\\u043d\\u043d\\u043e \\u043f\\u0435\\u0440\\u0432\\u044b\\u0435 2-3 \\u0434\\u043d\\u044f \\u0438\\u0441\\u043a\\u0440\\u0435\\u043d\\u043d\\u0435 \\u0445\\u043e\\u0442\\u0435\\u043b\\u043e\\u0441\\u044c \\u043f\\u043e\\u0441\\u043b\\u0430\\u0442\\u044c \\u043f\\u0440\\u0438\\u0441\\u0442\\u0430\\u0432\\u0443\\u0447\\u0438\\u0445 \\u0442\\u0430\\u0439\\u0441\\u043a\\u0438\\u0445 \\u0434\\u0435\\u0432\\u0447\\u043e\\u043d\\u043e\\u043a , \\u043a\\u0430\\u043a \\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u0442\\u0441\\u044f , \\\" \\u043d\\u0430\\u0445 \\\" . \\u0420\\u0435\\u0441\\u043f\\u0435\\u043a\\u0442 \\u0430\\u0432\\u0442\\u043e\\u0440\\u0443 , \\u0447\\u0442\\u043e \\u043d\\u0435 \\u043f\\u043e\\u0441\\u0442\\u0435\\u0441\\u043d\\u044f\\u043b\\u0441\\u044f \\u044d\\u0442\\u043e \\u043e\\u0437\\u0432\\u0443\\u0447\\u0438\\u0442\\u044c ... 18 \\u044f\\u043d\\u0432 2009 , 04:00\",\n          \"\\u041d\\u0430 \\u0432\\u0442\\u043e\\u0440\\u043e\\u0439 \\u0434\\u0435\\u043d\\u044c \\u043e\\u0447\\u0435\\u043d\\u044c \\u043c\\u043d\\u043e\\u0433\\u043e \\u043c\\u0435\\u0441\\u0442 \\u0437\\u0430\\u043b\\u043e\\u0436\\u0438\\u043b\\u0438 \\u043d\\u0430 \\u043c\\u043e\\u0439 \\u0432\\u0437\\u0433\\u043b\\u044f\\u0434 . \\u0412\\u0441\\u0435 \\u043c\\u0435\\u0441\\u0442\\u0430 \\u043d\\u0430\\u0439\\u0442\\u0438 \\u043b\\u0435\\u0433\\u043a\\u043e . \\u041e\\u0442\\u0435\\u043b\\u0438 \\u0438 \\u0433\\u0435\\u0441\\u0442\\u044b \\u0432 \\u043f\\u0440\\u0438\\u043d\\u0446\\u0438\\u043f\\u0435 \\u0442\\u043e\\u0436\\u0435 \\u043f\\u0440\\u043e\\u0431\\u043b\\u0435\\u043c \\u043d\\u0435 \\u0434\\u043e\\u043b\\u0436\\u043d\\u043e \\u0431\\u044b\\u0442\\u044c \\u0442\\u0435\\u043c \\u0431\\u043e\\u043b\\u0435\\u0435 \\u043f\\u0440\\u0430\\u0437\\u0434\\u043d\\u0438\\u043a\\u0438 \\u0443\\u0436\\u0435 \\u043f\\u0440\\u0430\\u043a\\u0442\\u0438\\u0447\\u0435\\u0441\\u043a\\u0438 \\u043f\\u0440\\u043e\\u0448\\u043b\\u0438 , \\u0442\\u0430\\u043a \\u0447\\u0442\\u043e \\u0444\\u0443\\u043b\\u043b \\u0432 \\u043d\\u0438\\u0445 \\u0432\\u0440\\u044f\\u0434 \\u043b\\u0438 \\u0431\\u0443\\u0434\\u0435\\u0442 . 05 \\u044f\\u043d\\u0432 2012 , 18:01\",\n          \"\\u0428\\u0430\\u043b\\u0442\\u0438\\u0431\\u0430\\u0440\\u0449\\u0430\\u0439 \\u041a\\u043b\\u0430\\u0441\\u0441\\u0438\\u0447\\u0435\\u0441\\u043a\\u043e\\u0435 \\u0431\\u043b\\u044e\\u0434\\u043e \\u043b\\u0438\\u0442\\u043e\\u0432\\u0441\\u043a\\u043e\\u0439 \\u043d\\u0430\\u0446\\u0438\\u043e\\u043d\\u0430\\u043b\\u044c\\u043d\\u043e\\u0439 \\u043a\\u0443\\u0445\\u043d\\u0438 , \\u043d\\u0430 \\u0435\\u0433\\u043e \\u0440\\u043e\\u0434\\u0438\\u043d\\u0435 \\u043d\\u0430\\u0437\\u044b\\u0432\\u0430\\u0435\\u043c\\u043e\\u0435 altibariai ( \\u0448\\u0430\\u043b\\u0442\\u0438\\u0431\\u0430\\u0440\\u0449\\u0430\\u0439 , \\u0445\\u043e\\u043b\\u043e\\u0434\\u043d\\u044b\\u0439 \\u0431\\u043e\\u0440\\u0449 ) . \\u0415\\u0433\\u043e , \\u043f\\u043e\\u0436\\u0430\\u043b\\u0443\\u0439 , \\u043c\\u043e\\u0436\\u043d\\u043e \\u0441\\u0447\\u0438\\u0442\\u0430\\u0442\\u044c \\u0440\\u043e\\u0434\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u0438\\u043a\\u043e\\u043c \\u043f\\u0440\\u0438\\u0432\\u044b\\u0447\\u043d\\u044b\\u043c \\u0434\\u043b\\u044f \\u043d\\u0430\\u0441 \\u043e\\u043a\\u0440\\u043e\\u0448\\u043a\\u0438 \\u0438 \\u0431\\u043e\\u0440\\u0449\\u0430 . \\u041f\\u0440\\u043e\\u0434\\u0443\\u043a\\u0442\\u044b : 0,5 \\u043b\\u0438\\u0442\\u0440\\u0430 \\u043a\\u0435\\u0444\\u0438\\u0440\\u0430 ( \\u043d\\u0435 \\u043e\\u0431\\u0435\\u0437\\u0436\\u0438\\u0440\\u0435\\u043d\\u043d\\u044b\\u0439 , \\u043e\\u0442 1 \\u0434\\u043e 7 % \\u0436\\u0438\\u0440\\u043d\\u043e\\u0441\\u0442\\u0438 ) ; 1 \\u043a\\u0440\\u0443\\u043f\\u043d\\u0430\\u044f \\u0438\\u043b\\u0438 2 \\u043d\\u0435\\u0431\\u043e\\u043b\\u044c\\u0448\\u0438\\u0445 \\u0442\\u0435\\u043c\\u043d\\u043e-\\u043a\\u0440\\u0430\\u0441\\u043d\\u044b\\u0445 \\u0441\\u0432\\u0435\\u043a\\u043b\\u044b ; 100 \\u0433\\u0440\\u0430\\u043c\\u043c \\u0445\\u043e\\u043b\\u043e\\u0434\\u043d\\u043e\\u0439 \\u0432\\u043e\\u0434\\u044b ; 1-2 \\u044f\\u0439\\u0446\\u043e ; 2 \\u043a\\u0430\\u0440\\u0442\\u043e\\u0444\\u0435\\u043b\\u0438\\u043d\\u044b ; \\u0437\\u0435\\u043b\\u0435\\u043d\\u044c ( \\u043b\\u0443\\u043a , \\u0443\\u043a\\u0440\\u043e\\u043f , \\u043f\\u0435\\u0442\\u0440\\u0443\\u0448\\u043a\\u0430 \\u043f\\u043e \\u0432\\u043a\\u0443\\u0441\\u0443 ) ; \\u0441\\u043e\\u043b\\u044c . \\u041f\\u0440\\u0438\\u0433\\u043e\\u0442\\u043e\\u0432\\u043b\\u0435\\u043d\\u0438\\u0435 : \\u0422\\u0449\\u0430\\u0442\\u0435\\u043b\\u044c\\u043d\\u043e \\u043c\\u043e\\u0435\\u043c \\u044f\\u0439\\u0446\\u043e , \\u043a\\u0430\\u0440\\u0442\\u043e\\u0444\\u0435\\u043b\\u044c \\u0438 \\u0441\\u0432\\u0435\\u043a\\u043b\\u0443 , \\u043d\\u0430\\u043c \\u043d\\u0443\\u0436\\u043d\\u043e \\u0431\\u0443\\u0434\\u0435\\u0442 \\u043e\\u0442\\u0432\\u0430\\u0440\\u0438\\u0442\\u044c \\u0438\\u0445 \\u0434\\u043e \\u0433\\u043e\\u0442\\u043e\\u0432\\u043d\\u043e\\u0441\\u0442\\u0438 . \\u041a\\u0430\\u0437\\u0430\\u043b\\u043e\\u0441\\u044c \\u0431\\u044b , \\u0447\\u0442\\u043e \\u043c\\u043e\\u0436\\u0435\\u0442 \\u0431\\u044b\\u0442\\u044c \\u043f\\u0440\\u043e\\u0449\\u0435 ? \\u041d\\u043e \\u0432\\u0430\\u0440\\u043a\\u0430 \\u043a\\u0430\\u0436\\u0434\\u043e\\u0433\\u043e \\u0438\\u0437 \\u044d\\u0442\\u0438\\u0445 \\u043f\\u0440\\u043e\\u0434\\u0443\\u043a\\u0442\\u043e\\u0432 \\u0438\\u043c\\u0435\\u0435\\u0442 \\u0441\\u0432\\u043e\\u0438 \\u043e\\u0441\\u043e\\u0431\\u0435\\u043d\\u043d\\u043e\\u0441\\u0442\\u0438 . \\u041c\\u0438\\u0440\\u0421\\u043e\\u0432\\u0435\\u0442\\u043e\\u0432 \\u0440\\u0430\\u0441\\u0441\\u043a\\u0430\\u0436\\u0435\\u0442 \\u043e \\u043d\\u0438\\u0445 \\u043f\\u043e\\u0434\\u0440\\u043e\\u0431\\u043d\\u0435\\u0435 . \\u041d\\u0430\\u0447\\u043d\\u0435\\u043c \\u0441\\u043e \\u0441\\u0432\\u0435\\u043a\\u043b\\u044b , \\u0442 . \\u043a . \\u043e\\u043d\\u0430 \\u0432\\u0430\\u0440\\u0438\\u0442\\u0441\\u044f \\u0434\\u043e\\u043b\\u044c\\u0448\\u0435 \\u0432\\u0441\\u0435\\u0445 . \\u041a\\u043e\\u0433\\u0434\\u0430 \\u0441\\u0432\\u0435\\u043a\\u043b\\u0430 \\u0431\\u0443\\u0434\\u0435\\u0442 \\u0433\\u043e\\u0442\\u043e\\u0432\\u0430 ( \\u0438\\u043b\\u0438 \\u043f\\u043e\\u0447\\u0442\\u0438 \\u0433\\u043e\\u0442\\u043e\\u0432\\u0430 ) , \\u043e\\u0442\\u0432\\u0430\\u0440\\u0438\\u0432\\u0430\\u0435\\u043c \\u043a\\u0430\\u0440\\u0442\\u043e\\u0444\\u0435\\u043b\\u044c . \\u041f\\u0440\\u0438\\u0447\\u0435\\u043c \\u0434\\u043b\\u044f \\u0448\\u0430\\u043b\\u0442\\u0438\\u0431\\u0430\\u0440\\u0449\\u0430\\u0439 \\u0435\\u0433\\u043e \\u043b\\u0443\\u0447\\u0448\\u0435 \\u0432\\u0430\\u0440\\u0438\\u0442\\u044c \\u0432 \\u043e\\u0447\\u0438\\u0449\\u0435\\u043d\\u043d\\u043e\\u043c \\u0432\\u0438\\u0434\\u0435 , \\u0430 \\u043d\\u0435 \\u0432 \\u043c\\u0443\\u043d\\u0434\\u0438\\u0440\\u0435 . \\u042f\\u0439\\u0446\\u0430 \\u043e\\u0442\\u0432\\u0430\\u0440\\u0438\\u0432\\u0430\\u0435\\u043c \\u0432\\u043a\\u0440\\u0443\\u0442\\u0443\\u044e . \\u0421\\u0432\\u0430\\u0440\\u0435\\u043d\\u043d\\u044b\\u0435 \\u0434\\u043e \\u0433\\u043e\\u0442\\u043e\\u0432\\u043d\\u043e\\u0441\\u0442\\u0438 \\u044f\\u0439\\u0446\\u0430 \\u043e\\u0445\\u043b\\u0430\\u0436\\u0434\\u0430\\u0435\\u043c \\u043f\\u043e\\u0434 \\u0441\\u0442\\u0440\\u0443\\u0435\\u0439 \\u0445\\u043e\\u043b\\u043e\\u0434\\u043d\\u043e\\u0439 \\u0432\\u043e\\u0434\\u044b . \\u0411\\u043b\\u0430\\u0433\\u043e\\u0434\\u0430\\u0440\\u044f \\u044d\\u0442\\u043e\\u043c\\u0443 \\u043d\\u0435\\u0445\\u0438\\u0442\\u0440\\u043e\\u043c\\u0443 \\u043f\\u0440\\u0438\\u0435\\u043c\\u0443 \\u043e\\u043d\\u0438 \\u0431\\u0443\\u0434\\u0443\\u0442 \\u043d\\u0430\\u043c\\u043d\\u043e\\u0433\\u043e \\u043b\\u0443\\u0447\\u0448\\u0435 \\u0447\\u0438\\u0441\\u0442\\u0438\\u0442\\u044c\\u0441\\u044f . \\u041e\\u0447\\u0438\\u0449\\u0435\\u043d\\u043d\\u044b\\u0435 \\u0438 \\u043e\\u0441\\u0442\\u044b\\u0432\\u0448\\u0438\\u0435 \\u044f\\u0439\\u0446\\u0430 \\u043d\\u0430\\u0440\\u0435\\u0437\\u0430\\u0435\\u043c \\u0442\\u043e\\u043d\\u043a\\u0438\\u043c\\u0438 \\u0434\\u043e\\u043b\\u044c\\u043a\\u0430\\u043c\\u0438 . \\u041c\\u043e\\u0435\\u043c \\u0438 \\u043c\\u0435\\u043b\\u043a\\u043e \\u043d\\u0430\\u0440\\u0435\\u0437\\u0430\\u0435\\u043c \\u0437\\u0435\\u043b\\u0435\\u043d\\u044c . \\u0418\\u0437 \\u0437\\u0435\\u043b\\u0435\\u043d\\u0438 \\u043f\\u043e\\u0442\\u0440\\u0435\\u0431\\u0443\\u0435\\u0442\\u0441\\u044f \\u0442\\u043e\\u043b\\u044c\\u043a\\u043e \\u043b\\u0443\\u043a , \\u0443\\u043a\\u0440\\u043e\\u043f \\u0438 ( \\u0438\\u043b\\u0438 ) \\u043f\\u0435\\u0442\\u0440\\u0443\\u0448\\u043a\\u0430 \\u0412 \\u043a\\u0435\\u0444\\u0438\\u0440 \\u0434\\u043e\\u0431\\u0430\\u0432\\u043b\\u044f\\u0435\\u043c \\u0441\\u043e\\u043b\\u044c ( \\u043f\\u043e \\u0432\\u043a\\u0443\\u0441\\u0443 ) , \\u0441\\u043b\\u0435\\u0433\\u043a\\u0430 \\u0432\\u0437\\u0431\\u0438\\u0432\\u0430\\u0435\\u043c \\u0435\\u0433\\u043e . \\u041f\\u0443\\u0441\\u0442\\u044c \\u0431\\u0443\\u0434\\u0435\\u0442 \\u0441\\u043b\\u0435\\u0433\\u043a\\u0430 \\u043f\\u0435\\u0440\\u0435\\u0441\\u043e\\u043b\\u0435\\u043d , \\u043d\\u0430 \\u0433\\u0440\\u0430\\u043d\\u0438 , \\u043f\\u043e\\u0442\\u043e\\u043c\\u0443 \\u0447\\u0442\\u043e \\u0437\\u0430\\u0442\\u0435\\u043c \\u043c\\u044b \\u0434\\u043e\\u0431\\u0430\\u0432\\u043b\\u044f\\u0435\\u043c \\u043a \\u043d\\u0435\\u043c\\u0443 \\u0445\\u043e\\u043b\\u043e\\u0434\\u043d\\u0443\\u044e \\u0432\\u043e\\u0434\\u0443 . \\u0421\\u043e\\u043b\\u044c \\u0432 \\u043a\\u0435\\u0444\\u0438\\u0440\\u0435 \\u043f\\u0440\\u043e\\u0449\\u0435 \\u0440\\u0430\\u0441\\u0442\\u0432\\u043e\\u0440\\u0438\\u0442\\u044c , \\u043f\\u043e\\u044d\\u0442\\u043e\\u043c\\u0443 \\u0434\\u043e\\u0431\\u0430\\u0432\\u043b\\u044f\\u0435\\u043c \\u0435\\u0435 \\u0438\\u043c\\u0435\\u043d\\u043d\\u043e \\u043d\\u0430 \\u044d\\u0442\\u043e\\u043c \\u044d\\u0442\\u0430\\u043f\\u0435 . \\u0422\\u0435\\u043f\\u0435\\u0440\\u044c \\u0442\\u0449\\u0430\\u0442\\u0435\\u043b\\u044c\\u043d\\u043e \\u043f\\u0435\\u0440\\u0435\\u043c\\u0435\\u0448\\u0438\\u0432\\u0430\\u0435\\u043c , \\u0441\\u043d\\u043e\\u0432\\u0430 \\u043d\\u0435\\u043c\\u043d\\u043e\\u0433\\u043e \\u0432\\u0437\\u0431\\u0438\\u0432 \\u0441\\u043c\\u0435\\u0441\\u044c \\u0434\\u043e \\u043f\\u043e\\u044f\\u0432\\u043b\\u0435\\u043d\\u0438\\u044f \\u043f\\u0443\\u0437\\u044b\\u0440\\u044c\\u043a\\u043e\\u0432 . \\u0412 \\u043a\\u0430\\u0441\\u0442\\u0440\\u044e\\u043b\\u0435 \\u0437\\u0430\\u043b\\u0438\\u0432\\u0430\\u0435\\u043c \\u043d\\u0430\\u0440\\u0435\\u0437\\u0430\\u043d\\u043d\\u0443\\u044e \\u0441\\u0432\\u0435\\u043a\\u043b\\u0443 \\u0441\\u043c\\u0435\\u0441\\u044c\\u044e \\u043a\\u0435\\u0444\\u0438\\u0440\\u0430 \\u0438 \\u0432\\u043e\\u0434\\u044b , \\u0434\\u043e\\u0431\\u0430\\u0432\\u043b\\u044f\\u0435\\u043c \\u043f\\u043e\\u043b\\u043e\\u0432\\u0438\\u043d\\u0443 \\u043d\\u0430\\u0440\\u0435\\u0437\\u0430\\u043d\\u043d\\u043e\\u0439 \\u0437\\u0435\\u043b\\u0435\\u043d\\u0438 . \\u0422\\u0449\\u0430\\u0442\\u0435\\u043b\\u044c\\u043d\\u043e \\u0432\\u044b\\u043c\\u0435\\u0448\\u0438\\u0432\\u0430\\u0435\\u043c . \\u0412\\u043e\\u0442 \\u0438 \\u0432\\u0441\\u0435 , \\u0448\\u0430\\u043b\\u0442\\u0438\\u0431\\u0430\\u0440\\u0449\\u0430\\u0439 \\u0433\\u043e\\u0442\\u043e\\u0432 . \\u041d\\u043e \\u043d\\u0435\\u0443\\u0436\\u0435\\u043b\\u0438 \\u043c\\u044b \\u043d\\u0430\\u043f\\u0440\\u0430\\u0441\\u043d\\u043e \\u0432\\u0430\\u0440\\u0438\\u043b\\u0438 \\u043a\\u0430\\u0440\\u0442\\u043e\\u0444\\u0435\\u043b\\u044c \\u0438 \\u044f\\u0439\\u0446\\u0430 ? \\u041d\\u0435\\u0442 , \\u043d\\u0438 \\u0432 \\u043a\\u043e\\u0435\\u043c \\u0441\\u043b\\u0443\\u0447\\u0430\\u0435 . \\u042f\\u0439\\u0446\\u0430 \\u0432\\u044b\\u043a\\u043b\\u0430\\u0434\\u044b\\u0432\\u0430\\u0435\\u043c \\u0432 \\u0442\\u0430\\u0440\\u0435\\u043b\\u043a\\u0443 \\u0441 \\u043b\\u0438\\u0442\\u043e\\u0432\\u0441\\u043a\\u0438\\u043c \\u0445\\u043e\\u043b\\u043e\\u0434\\u043d\\u044b\\u043c \\u0431\\u043e\\u0440\\u0449\\u043e\\u043c \\u0438 \\u043f\\u043e\\u0441\\u044b\\u043f\\u0430\\u0435\\u043c \\u0431\\u043b\\u044e\\u0434\\u043e \\u0437\\u0435\\u043b\\u0435\\u043d\\u044c\\u044e . \\u0410 \\u043a\\u0430\\u0440\\u0442\\u043e\\u0444\\u0435\\u043b\\u044c \\u043f\\u043e\\u0434\\u0430\\u0435\\u0442\\u0441\\u044f \\u043d\\u0430 \\u0441\\u0442\\u043e\\u043b \\u0433\\u043e\\u0440\\u044f\\u0447\\u0438\\u043c , \\u0432\\u043c\\u0435\\u0441\\u0442\\u0435 \\u0441 \\u0448\\u0430\\u043b\\u0442\\u0438\\u0431\\u0430\\u0440\\u0449\\u0430\\u0435\\u043c , \\u043d\\u043e \\u043d\\u0430 \\u043e\\u0442\\u0434\\u0435\\u043b\\u044c\\u043d\\u043e\\u0439 \\u0442\\u0430\\u0440\\u0435\\u043b\\u043a\\u0435 . \\u0415\\u0433\\u043e \\u0442\\u043e\\u0436\\u0435 \\u043c\\u043e\\u0436\\u043d\\u043e \\u043f\\u043e\\u0441\\u044b\\u043f\\u0430\\u0442\\u044c \\u0440\\u0443\\u0431\\u043b\\u0435\\u043d\\u043e\\u0439 \\u0437\\u0435\\u043b\\u0435\\u043d\\u044c\\u044e . \\u0415\\u0433\\u043e \\u043c\\u043e\\u0436\\u043d\\u043e \\u043e\\u0442\\u043b\\u0430\\u043c\\u044b\\u0432\\u0430\\u0442\\u044c \\u043b\\u043e\\u0436\\u043a\\u043e\\u0439 \\u0438 \\u0435\\u0441\\u0442\\u044c \\u0432\\u043f\\u0440\\u0438\\u043a\\u0443\\u0441\\u043a\\u0443 \\u0441 \\u0431\\u043e\\u0440\\u0449\\u043e\\u043c , \\u0430 \\u043c\\u043e\\u0436\\u043d\\u043e \\u0442\\u043e\\u043b\\u043e\\u0447\\u044c \\u0432 \\u0442\\u0430\\u0440\\u0435\\u043b\\u043e\\u0447\\u043a\\u0435 \\u0438 \\u0434\\u043e\\u0431\\u0430\\u0432\\u043b\\u044f\\u0442\\u044c \\u0432 \\u0448\\u0430\\u043b\\u0442\\u0438\\u0431\\u0430\\u0440\\u0449\\u0430\\u0439 . \\u0421\\u043e\\u0447\\u0435\\u0442\\u0430\\u043d\\u0438\\u0435 \\u0445\\u043e\\u043b\\u043e\\u0434\\u043d\\u043e\\u0433\\u043e \\u0438 \\u0433\\u043e\\u0440\\u044f\\u0447\\u0435\\u0433\\u043e \\u0441\\u043d\\u0430\\u0447\\u0430\\u043b\\u0430 \\u043c\\u043e\\u0436\\u0435\\u0442 \\u043f\\u043e\\u043a\\u0430\\u0437\\u0430\\u0442\\u044c\\u0441\\u044f \\u0447\\u0438\\u0442\\u0430\\u0442\\u0435\\u043b\\u044f\\u043c \\u041c\\u0438\\u0440\\u0421\\u043e\\u0432\\u0435\\u0442\\u043e\\u0432 \\u043d\\u0435\\u0441\\u043a\\u043e\\u043b\\u044c\\u043a\\u043e \\u043d\\u0435\\u043f\\u0440\\u0438\\u0432\\u044b\\u0447\\u043d\\u044b\\u043c \\u0438 \\u0441\\u0442\\u0440\\u0430\\u043d\\u043d\\u044b\\u043c , \\u043d\\u043e , \\u0440\\u0430\\u0441\\u043f\\u0440\\u043e\\u0431\\u043e\\u0432\\u0430\\u0432 \\u0431\\u043b\\u044e\\u0434\\u043e , \\u043d\\u0435\\u0432\\u043e\\u0437\\u043c\\u043e\\u0436\\u043d\\u043e \\u043d\\u0435 \\u043e\\u0446\\u0435\\u043d\\u0438\\u0442\\u044c \\u043c\\u0443\\u0434\\u0440\\u043e\\u0441\\u0442\\u044c \\u0438 \\u0438\\u0437\\u044f\\u0449\\u0435\\u0441\\u0442\\u0432\\u043e \\u0442\\u0430\\u043a\\u043e\\u0433\\u043e \\u043a\\u0443\\u043b\\u0438\\u043d\\u0430\\u0440\\u043d\\u043e\\u0433\\u043e \\u0440\\u0435\\u0448\\u0435\\u043d\\u0438\\u044f , \\u043f\\u043e\\u0437\\u0432\\u043e\\u043b\\u044f\\u044e\\u0449\\u0435\\u0433\\u043e \\u0441\\u0440\\u0430\\u0432\\u043d\\u0438\\u0442\\u0435\\u043b\\u044c\\u043d\\u043e \\u043c\\u0430\\u043b\\u044b\\u043c\\u0438 \\u0441\\u0440\\u0435\\u0434\\u0441\\u0442\\u0432\\u0430\\u043c\\u0438 \\u0434\\u043e\\u0441\\u0442\\u0438\\u0447\\u044c \\u043d\\u0435\\u043e\\u0431\\u044b\\u0447\\u043d\\u043e\\u0433\\u043e \\u0432\\u043a\\u0443\\u0441\\u0430 . \\u0441\\u0441\\u044b\\u043b\\u043a\\u0430 \\u043d\\u0430 \\u0438\\u0441\\u0442\\u043e\\u0447\\u043d\\u0438\\u043a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25.157723527098668,\n        \"min\": 3.0,\n        \"max\": 99.0,\n        \"num_unique_values\": 75,\n        \"samples\": [\n          43.0,\n          75.0,\n          90.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genre\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"M\",\n          \"W\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"confounder\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JuCsdGNh47_S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "8c6e6476-8105-4aba-876d-203695c70d91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([5896.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
              "        6028.]),\n",
              " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "train_df = pd.read_csv('shift_train_75_mail_25_awd.csv')\n",
        "train_df['genre'] = train_df.genre.values == 'M'\n",
        "train_df['text'] = train_df.sentence.values\n",
        "train_df = train_df.sample(frac=1.0, random_state=42)\n",
        "\n",
        "dev_df = pd.read_csv('awd_test_topics.csv')\n",
        "dev_df['genre'] = dev_df.genre.values == 'M'\n",
        "dev_df['text'] = dev_df.sentence.values\n",
        "dev_df['confounder'] = 1\n",
        "dev_df = dev_df.sample(frac=1.0, random_state=42)\n",
        "\n",
        "\n",
        "test_df = pd.read_csv('mail_test_topics.csv')\n",
        "test_df['genre'] = test_df.genre.values == 'M'\n",
        "test_df['text'] = test_df.sentence.values\n",
        "test_df['confounder'] = 0\n",
        "test_df = test_df.sample(frac=1.0, random_state=42)\n",
        "\n",
        "train_df['split'] = 'train'\n",
        "dev_df['split'] = 'dev'\n",
        "test_df['split'] = 'test'\n",
        "df = pd.concat([train_df, dev_df, test_df])\n",
        "df = df.reset_index()\n",
        "df['index'] = df.index\n",
        "\n",
        "\n",
        "train_indexes = df.index[df['split'] == 'train'].tolist()\n",
        "dev_indexes = df.index[df['split'] == 'dev'].tolist()\n",
        "test_indexes = df.index[df['split'] == 'test'].tolist()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "vad = np.array([[int(v), int(c)] for v, c in zip(df['genre'].values, df['confounder'].values)])\n",
        "plt.hist(vad[:, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NuscTI53sB3X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gw8W9OuZBXlN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "lengths = [len(str(text).split()) for text in df.sentence.values]\n",
        "print(np.median(lengths))\n",
        "print(np.percentile([len(str(text).split()) for text in df.text.values], 75))\n",
        "print(np.percentile([len(str(text).split()) for text in df.text.values], 90))\n",
        "\n",
        "plt.hist(lengths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "1OoYag3PA_qt",
        "outputId": "1110f8d5-804c-4cd8-d586-1b63bd4bd560"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68.0\n",
            "117.0\n",
            "221.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.1776e+04, 9.8000e+01, 2.6000e+01, 1.0000e+01, 6.0000e+00,\n",
              "        3.0000e+00, 0.0000e+00, 2.0000e+00, 2.0000e+00, 1.0000e+00]),\n",
              " array([5.0000e+00, 1.1057e+03, 2.2064e+03, 3.3071e+03, 4.4078e+03,\n",
              "        5.5085e+03, 6.6092e+03, 7.7099e+03, 8.8106e+03, 9.9113e+03,\n",
              "        1.1012e+04]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZSNd4sWG3jx"
      },
      "source": [
        "# 3. Tokenization & Input Formatting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m9jpFqPHCsS"
      },
      "source": [
        "## 3.1. BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "T9GQcNm9RUI6",
        "outputId": "198087a7-ff21-4045-f05f-8a4486cac4c7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2e90646107ad>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the BERT tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading BERT tokenizer...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1782\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1783\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1781\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1791\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1794\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m             raise RuntimeError(\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpackaging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfx_traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aot_autograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtree_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcapture_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoggingTensorMode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/functional_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_subclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunctionalTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_subclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_sparse_any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_shapes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefinitely_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msym_eq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreductions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStorageWeakRef\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m from torch.utils._python_dispatch import (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mShapeGuard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_dispatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_traceable_wrapper_subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m from torch.utils._sympy.functions import (\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mApplication\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloorDiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPythonMod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIsNonOverlappingAndDenseIndicator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCleanDiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloorToInt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCeilToInt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_sympy/functions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msympify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlazy_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'dev'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBasic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAtom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msingleton\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAtomicExpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnevaluatedExpr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msymbol\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDummy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnumbers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRational\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInteger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumberSymbol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/core/expr.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBasic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAtom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msingleton\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mevalf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvalfMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpure_complex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_MAXPREC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdecorators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcall_highest_priority\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msympify_method_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msympify_return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcacheit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/core/evalf.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msympify\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msympify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msingleton\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgmpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSYMPY_INTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambdify\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlambdify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/external/gmpy.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpythonmpq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPythonMPQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m from .ntheory import (\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mbit_scan1\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpython_bit_scan1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mbit_scan0\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpython_bit_scan0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertModel, AdamW\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "\n",
        "# Uncased means that the text has been lower cased before Word Piece\n",
        "# tokenization, e.g., John Smith becomes john smith. The Uncased model also\n",
        "# strips out any accent markers\n",
        "bert_pretrained_model_name = 'google-bert/bert-base-multilingual-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_pretrained_model_name)#, do_lower_case=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBaX4Rg6HSWu"
      },
      "source": [
        "## 3.2. Tokenize Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi-pNicXahW_"
      },
      "source": [
        "Perform one tokenization pass of the dataset in order to measure the maximum sentence length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXH-KvBoaZOs"
      },
      "outputs": [],
      "source": [
        "def get_max_sentence_length(sentences):\n",
        "  max_len = 0\n",
        "\n",
        "  # For every sentence...\n",
        "  for sent in sentences:\n",
        "\n",
        "      # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "      input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "      input_ids = input_ids[:300]\n",
        "\n",
        "      # Update the maximum sentence length.\n",
        "      max_len = max(max_len, len(input_ids))\n",
        "\n",
        "  return max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lu39B4IZaZ51"
      },
      "outputs": [],
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "max_sentence_length = get_max_sentence_length(sentences)\n",
        "\n",
        "# For every sentence...\n",
        "for sentence in sentences:\n",
        "  # `encode_plus` will:\n",
        "  #   (1) Tokenize the sentence.\n",
        "  #   (2) Prepend the `[CLS]` token to the start.\n",
        "  #   (3) Append the `[SEP]` token to the end.\n",
        "  #   (4) Map tokens to their IDs.\n",
        "  #   (5) Pad or truncate the sentence to `max_length`\n",
        "  #   (6) Create attention masks for [PAD] tokens.\n",
        "  encoded_dict = tokenizer.encode_plus(\n",
        "      sentence,                         # Sentence to encode.\n",
        "      add_special_tokens = True,    # Add '[CLS]' and '[SEP]'\n",
        "      max_length = max_sentence_length,             # Pad & truncate all sentences.\n",
        "      truncation = True,            # Explicitely truncate sentences to max length.\n",
        "      pad_to_max_length = True,\n",
        "      return_attention_mask = True, # Construct attn. masks.\n",
        "      return_tensors = 'pt',        # Return pytorch tensors.\n",
        "      )\n",
        "\n",
        "  # Add the encoded sentence to the list.\n",
        "  input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "  # And its attention mask (simply differentiates padding from non-padding).\n",
        "  attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "outputs = torch.tensor(vad, dtype=torch.float32) # TODO: check if it's necessary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r846BmV2G6N"
      },
      "source": [
        "We’ll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GyB0G7Paa4p"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, Subset, DataLoader\n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks, outputs)\n",
        "\n",
        "train_dataset = Subset(dataset, train_indexes)\n",
        "dev_dataset = Subset(dataset, dev_indexes)\n",
        "test_dataset = Subset(dataset, test_indexes)\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it\n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch\n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order.\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            shuffle = True, # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "dev_dataloader = DataLoader(\n",
        "            dev_dataset, # The validation samples.\n",
        "            shuffle = False, # Default: Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset, # The test samples.\n",
        "            shuffle = False, # Default: Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCpQIk8XHsvv"
      },
      "source": [
        "# 4. Train Our Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG0BP-gkIE_q"
      },
      "source": [
        "## 4.1. Create a Bert model with a regression layer on top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAvgJG2MnCj_"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# Bert Model transformer with a sequence regression head on top (a linear\n",
        "# layer on top of the pooled output).\n",
        "class BertForSequenceRegression(nn.Module):\n",
        "  def __init__(self, bert_pretrained_model_name, output_size):\n",
        "    super(BertForSequenceRegression, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(bert_pretrained_model_name,\n",
        "                                          output_attentions = False,\n",
        "                                          output_hidden_states = False)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, output_size)\n",
        "    self.ae = nn.Linear(self.bert.config.hidden_size, output_size)\n",
        "\n",
        "  def forward(self, input_sentence, input_mask):\n",
        "    last_hidden_states = self.bert(input_sentence, attention_mask=input_mask)[1]\n",
        "    output = nn.functional.sigmoid(self.out(last_hidden_states))\n",
        "    ae = nn.functional.sigmoid(self.ae(last_hidden_states))\n",
        "    return (output, ae)\n",
        "\n",
        "model = BertForSequenceRegression(bert_pretrained_model_name, output_size=1)\n",
        "\n",
        "# freeze some layers (top | middle | bottom):\n",
        "bottom = range(2, 12)\n",
        "middle = list(range(0,5))+list(range(7,12))\n",
        "top = range(0, 6)\n",
        "\n",
        "layersToFreeze = []\n",
        "for i in layersToFreeze:\n",
        "  print(i)\n",
        "  for param in model.bert.encoder.layer[i].parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Tell pytorch to run this model on the GPU\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVTz-k9PH-5d"
      },
      "source": [
        "## 4.2. Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo1LuJn7NdPH"
      },
      "source": [
        "Helper function for formatting elapsed times as hh:mm:ss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGqWolARNcX7"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCVePSh0GNJ5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKkR-6VIUCMv"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Optimizer (ADAM is a fancy version of SGD) lr options: 2e-5, 3e-5, 5e-5\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-5, eps=1e-8)\n",
        "\n",
        "epochs = 7\n",
        "\n",
        "# Loss function\n",
        "ce_criterion = torch.nn.BCELoss()\n",
        "ae_criterion = torch.nn.BCELoss()\n",
        "lambd = 0.0\n",
        "m = 4\n",
        "\n",
        "# We'll store a number of quantities such as training loss and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "  if epoch_i % 2 == 0:\n",
        "    for param in model.ae.parameters():\n",
        "        param.require_grad = False\n",
        "    for param in model.out.parameters():\n",
        "        param.require_grad = True\n",
        "    for param in model.bert.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "  else:\n",
        "    for param in model.ae.parameters():\n",
        "        param.require_grad = True\n",
        "    for param in model.out.parameters():\n",
        "        param.require_grad = False\n",
        "    for param in model.bert.parameters():\n",
        "        param.requires_grad = False\n",
        "  # ========================================\n",
        "  #               Training\n",
        "  # ========================================\n",
        "\n",
        "  # Perform one full pass over the training set.\n",
        "\n",
        "  print(\"\")\n",
        "  print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "  print('Training...')\n",
        "\n",
        "  # Measure how long the training epoch takes.\n",
        "  t0 = time.time()\n",
        "\n",
        "  # Reset the total loss for this epoch.\n",
        "  total_train_loss = 0\n",
        "\n",
        "  # Put the model into training mode.\n",
        "  # Dropout layers behave differently during training vs. eval mode.\n",
        "  model.train()\n",
        "\n",
        "  # For each batch of training data...\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "    # Progress update every 40 batches.\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "\n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    # zero gradients\n",
        "    optimizer.zero_grad()\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Perform a forward pass (evaluate the model on this training batch).\n",
        "    output, ae = model(b_input_ids, b_input_mask)\n",
        "    source_ids = b_labels[:, 1].view(-1) == 1.0\n",
        "    target_ids = b_labels[:, 1].view(-1) == 0.0\n",
        "\n",
        "    # loss\n",
        "    if epoch_i % 2 == 0:\n",
        "      loss = ce_criterion(output.view(-1), b_labels[:, 0].view(-1)) - lambd * ae_criterion(ae.view(-1), b_labels[:, 1].view(-1))\n",
        "    else:\n",
        "      loss = ae_criterion(ae.view(-1), b_labels[:, 1].view(-1))\n",
        "    total_train_loss += loss.item()\n",
        "\n",
        "    # Perform a backward pass to calculate the gradients.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters and take a step using the computed gradient.\n",
        "    # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "    # modified based on their gradients, the learning rate, etc.\n",
        "    optimizer.step()\n",
        "\n",
        "  # Calculate the average loss over all of the batches.\n",
        "  avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "  # Measure how long this epoch took.\n",
        "  training_time = format_time(time.time() - t0)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "  print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "  # ========================================\n",
        "  #               Validation\n",
        "  # ========================================\n",
        "  # After the completion of each training epoch, measure our performance on\n",
        "  # our validation set.\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Running Validation...\")\n",
        "\n",
        "  t0 = time.time()\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables\n",
        "  total_eval_accuracy = 0\n",
        "  total_size = 0\n",
        "  total_eval_loss = 0\n",
        "  nb_eval_steps = 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in dev_dataloader:\n",
        "\n",
        "    # Unpack this training batch from our dataloader.\n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
        "    # the `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids\n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():\n",
        "\n",
        "      # Perform a forward pass\n",
        "      output = model(b_input_ids, b_input_mask)[0]\n",
        "\n",
        "    # loss\n",
        "    loss = ce_criterion(output.view(-1), b_labels[:, 0].view(-1))\n",
        "    total_eval_accuracy += torch.sum((output.view(-1) >= 0.5) == b_labels[:, 0].view(-1))\n",
        "    total_size += output.size()[0]\n",
        "\n",
        "    # Accumulate the development loss.\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "  # Calculate the average loss over all of the batches.\n",
        "  avg_val_loss = total_eval_loss / len(dev_dataloader)\n",
        "\n",
        "  # Measure how long the development run took.\n",
        "  validation_time = format_time(time.time() - t0)\n",
        "\n",
        "  print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "  print(\"  Validation Acc: {0:.3f}\".format(total_eval_accuracy / total_size))\n",
        "  print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "  # Record all statistics from this epoch.\n",
        "  training_stats.append(\n",
        "      {\n",
        "          'epoch': epoch_i + 1,\n",
        "          'Training Loss': avg_train_loss,\n",
        "          'Training Time': training_time,\n",
        "          'Valid. Loss': avg_val_loss,\n",
        "          'Validation Time': validation_time\n",
        "      })\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CoMMFk-TkYs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46JdqZssf1Pu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with three decimal places.\n",
        "#pd.set_option('precision', 4)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ya44ZLK9UClM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glJ7rGlQJWQQ"
      },
      "source": [
        "# 5. Performance On Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjjC6kByUCsl"
      },
      "outputs": [],
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting values for {:,} test sentences...'.format(len(test_dataloader.dataset)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "total_test_loss = 0\n",
        "\n",
        "# Predict\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "for batch in test_dataloader:\n",
        "\n",
        "  # Add batch to GPU\n",
        "  b_input_ids = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_labels = batch[2].to(device)\n",
        "\n",
        "  # Telling the model not to compute or store gradients, saving memory and\n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Perform a forward pass\n",
        "    output, ae = model(b_input_ids, b_input_mask)\n",
        "\n",
        "  # loss\n",
        "  loss = ce_criterion(output.view(-1), b_labels[:, 0].view(-1))\n",
        "  all_predictions.append(output.view(-1).detach().cpu().numpy())\n",
        "  all_labels.append(b_labels[:, 0].view(-1).detach().cpu().numpy())\n",
        "  # Accumulate the development loss.\n",
        "  total_test_loss += loss.item()\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "\n",
        "print(avg_test_loss)\n",
        "print('    DONE.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_predictions = np.concatenate(all_predictions)\n",
        "all_labels = np.concatenate(all_labels)"
      ],
      "metadata": {
        "id": "uvTNy9NSX8o1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean([label == (pred >= 0.5) for label, pred in zip(all_labels, all_predictions)]))"
      ],
      "metadata": {
        "id": "KjoDyaGxOUL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSagmcRhsQQO"
      },
      "outputs": [],
      "source": [
        "all_predictions >= 0.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(all_predictions)"
      ],
      "metadata": {
        "id": "y49lJQIuOfJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ruVGYNsNOaGX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kejKxBo8Ari"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rfrQ8Vb8Ari"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyCADiYE8Ari"
      },
      "outputs": [],
      "source": [
        "#print('mean abs', np.mean(np.abs(all_predictions - df[df.split == \"test\"].education.values)))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qE7OyEI_8Arj"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.scatter(df[df.split == \"test\"].age.values, all_predictions)\n",
        "plt.xlabel('ground_true')\n",
        "plt.ylabel('prediction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6NE9yWF8Arj"
      },
      "outputs": [],
      "source": [
        "np.corrcoef(df[df.split == \"test\"].genre.values, all_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all"
      ],
      "metadata": {
        "id": "93-K2RE4xo4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "gNxmkY2_0iZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_predictions)"
      ],
      "metadata": {
        "id": "Z8cpBT3TNwvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mp4kxZ4LN6zz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}